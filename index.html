<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kyungho Bae</title>

    <meta name="author" content="Kyungho Bae">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kyungho Bae (배경호)
                </p>
                <p>
                  I'm a machine learning engineer at <a href="https://about.daangn.com/">Karrot(daangn)</a>.
                  I received my M.S. in Artificial Intelligence from Kyung Hee University, where I worked under the supervision of
                  <a href="https://sites.google.com/site/jchoivision/">Prof. Jinwoo Choi</a>.
                  During my graduate studies, I also worked as a research intern at <a href="https://www.lgresearch.ai/">LG AI Research</a>.
                </p>
                <p>
                  My research interests focus on video understanding, multimodal large language models, and representation learning,
                  with an emphasis on building robust and generalizable systems for complex real-world environments.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:backdrop9019@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Backdrop9019">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=yW4QOAoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://kr.linkedin.com/in/kyungho-bae-531466239">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/kyungho.png"><img style="width:220px;height:280px;object-fit: cover; border-radius: 20px;" alt="profile photo" src="images/kyungho.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <h3 style="margin-bottom: 5px; margin-top: 5px;">2025</h3>
                <ul style="margin-top: 5px;">
                  <li>(Jun.) One paper accepted to <em>ICCV 2025</em>.</li>
                  <li>(May) Joined <a href="https://about.daangn.com/">Karrot(daangn)</a> as a Machine Learning Engineer.</li>
                  <li>(Feb.) One paper accepted to <em>CVPR 2025</em> <strong><font color="red">(Highlight)</font></strong>.</li>
                </ul>
                <h3 style="margin-bottom: 5px; margin-top: 15px;">2024</h3>
                <ul style="margin-top: 5px;">
                  <li>(Jul.) One paper accepted to <em>ECCV 2024</em> <strong><font color="red">(Oral)</font></strong>.</li>
                  <li>(Jul.) Started internship as an AI Research Scientist at <a href="https://www.lgresearch.ai/">LG AI Research</a>.</li>
                </ul>
                <h3 style="margin-bottom: 5px; margin-top: 15px;">2023</h3>
                <ul style="margin-top: 5px;">
                  <li>(Oct.) One paper accepted to <em>WACV 2024</em>.</li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Employment</h2>
                <ul>
                  <li><b>Machine Learning Engineer</b><br>
                    <a href="https://about.daangn.com/">Karrot(daangn)</a>, May 2025 — Present<br>
                    Developing feed recommendation systems
                  </li>
                  <br>
                  <li><b>Research Intern</b><br>
                    <a href="https://www.lgresearch.ai/">LG AI Research</a>, Multi-modal Lab, July 2024 — March 2025<br>
                    Conducted research on video-LLMs
                  </li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <h4>(† indicates the first authors, * indicates the corresponding authors)</h4> -->
                <p>
                  I work on representation learning for video and multimodal understanding, with interests in domain adaptation, continual learning, and reducing bias in learned models.
                </p>
                <p>
                  The following are my recent publications. († indicates the first authors, * indicates the corresponding authors)
                </p>
                
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- <tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/continual.png" style="width:300px; height:auto; object-fit: contain; border: 1px solid #ccc; border-radius: 10px;" />
              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                A study on video continual learning.<br>
                <span><i>Under review</i></span><br>
              </td>
            </tr> -->


            <tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/continual.png" style="width:300px; height:auto; object-fit: contain; border: 1px solid #ccc; border-radius: 10px;" />
              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                <span class="papertitle">ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning</span><br>
                Jongseo Lee†, <span style="color: green;">Kyungho Bae†</span>, Kyle Min, Gyeong-Moon Park*, Jinwoo Choi*<br>
                <em>ICCV</em> 2025<br>
                <strong>Keywords:</strong> <em>Continual Learning, Video Action Recognition</em><br>
                <span style="color: gray;">arXiv coming soon</span>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/mash-vlm.png" style="width:300px; height:auto; object-fit: contain; border: 1px solid #ccc; border-radius: 10px;" />

              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                <span class="papertitle">MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal Representations</span><br>
                <span style="color: green;">Kyungho Bae</span>, Jinhyung Kim, Sihaeng Lee, Soonyoung Lee, Gunhee Lee*, Jinwoo Choi*<br>
                <em>CVPR</em> 2025 <strong><font color="red">(Highlight, acceptance rate = 3.71%)</font></strong><br>
                <strong>Keywords:</strong> <em>Hallucination, Video-LLM, Multimodal</em><br>
                <a href="https://arxiv.org/abs/2503.15871">arXiv</a>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/devias.png" style="width:300px; height:auto; object-fit: contain; border: 1px solid #ccc; border-radius: 10px;" />
              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                <span class="papertitle">DEVIAS: Learning Disentangled Video Representations of Action and Scene for Holistic Video Understanding</span><br>
                <span style="color: green;">Kyungho Bae†</span>, Geo Ahn†, Youngrae Kim†, Jinwoo Choi*<br>
                <em>ECCV</em> 2024 <strong><font color="red">(Oral, acceptance rate = 2.33%)</font></strong><br>
                <strong>Keywords:</strong> <em>Video Representation, Bias in Video</em><br>
                <a href="https://arxiv.org/abs/2312.00826">arXiv</a> / <a href="https://github.com/KHU-VLL/DEVIAS">code</a>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:30%;vertical-align:middle">
                <img src="images/glad.png" style="width:300px; height:auto; object-fit: contain; border: 1px solid #ccc; border-radius: 10px;" />
              </td>
              <td style="padding:8px;width:70%;vertical-align:middle">
                <span class="papertitle">GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation</span><br>
                Hyogun Lee†, <span style="color: green;">Kyungho Bae†</span>, Yumin Ko, Seongjong Ha, Gyeongmoon Park*, Jinwoo Choi*<br>
                <em>WACV</em> 2024<br>
                <strong>Keywords:</strong> <em>Video Domain Adaptation</em><br>
                <a href="https://arxiv.org/abs/2311.12467">arXiv</a> / <a href="https://github.com/KHU-VLL/GLAD">code</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Education</h2>
                <ul>
                  <li><b>Kyung Hee University, Korea</b><br>
                    M.S. in Artificial Intelligence, 2022 — 2024<br>
                    Advisor: Prof. Jinwoo Choi
                  </li>
                  <br>
                  <li><b>Kyung Hee University, Korea</b><br>
                    B.S. in Computer Engineering, 2016 — 2022
                  </li>
                </ul>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Based on <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>. Modified by Kyungho Bae.
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </tbody></table>

    
  </body>
</html>
